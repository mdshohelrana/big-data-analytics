{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1029a4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (2.1.2+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (0.16.2+cpu)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (2.1.2+cpu)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (1.26.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow==2.8.0\n",
    "\n",
    "# install gpu \n",
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# install cpu version\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce5244eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "random.seed( 10 ) # set the random seed (for reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a75296b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSample(seqL,k,testFlag=False):\n",
    "    #returns a random sequence of integers of length = seqL\n",
    "    kthInt=0\n",
    "    x =  torch.zeros(seqL,20)\n",
    "    for i in range(0,seqL):\n",
    "        randomIntegerNumber = random.randint(0,9)\n",
    "        if i==k-1:\n",
    "            kthInt=randomIntegerNumber\n",
    "        if testFlag:\n",
    "            sys.stdout.write(str(randomIntegerNumber) + ' ')\n",
    "        x[i,randomIntegerNumber-1] = 1\n",
    "\n",
    "    if testFlag:\n",
    "            sys.stdout.write('--> ' + str(kthInt) + '\\n')\n",
    "    x=x.unsqueeze(1) #extra dimension for Batch\n",
    "    y=torch.tensor([kthInt]) #target is the number at kth position in the sequence \n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9301703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memorize (nn.Module):\n",
    "    def __init__(self,stateDim):\n",
    "        super(Memorize, self).__init__()\n",
    "        self.stateDim = stateDim\n",
    "        self.inputDim = 20  # integer is represented as 1 hot vector of dimension=10\n",
    "        self.outputDim = 20  # 10 nodes for 10 classes\n",
    "        # currently the model uses the 'LSTM' cell. You could try\n",
    "        # others like: tanh, GRU. See: https://github.com/pytorch/examples/blob/master/word_language_model/model.py#L11\n",
    "        self.lstm = nn.LSTM(self.inputDim, self.stateDim )\n",
    "        self.outputLayer = nn.Linear(self.stateDim, self.outputDim)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        X: [L,B,inputDim(=10)] dimensional input tensor\n",
    "            L: Sequence length\n",
    "            B: is the \"batch\" dimension. As we are training on \n",
    "               single examples, B = 1 for us.\n",
    "        \"\"\"\n",
    "        lstmOut,_ = self.lstm(x)\n",
    "        L,B,D  = lstmOut.size(0),lstmOut.size(1),lstmOut.size(2) # L is seq len, B is batch size and D is feature dimension\n",
    "        #lstmOut holds the outputs at all timesteps but we require  only the output at last time step (L-1)\n",
    "        lstmOut_lastTimeStep = lstmOut[L-1,0,:]\n",
    "        #print (lstmOut_lastTimeStep.size())\n",
    "        \n",
    "        #lstmOut = lstmOut.view(L*B,D)\n",
    "        outputLayerActivations = self.outputLayer(lstmOut_lastTimeStep)\n",
    "        #outputSoftMax=self.softmax(outputLayerActivations)\n",
    "        # project lstm states to \"output\"\n",
    "        \n",
    "    \n",
    "        return outputLayerActivations.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32087287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized\n",
      "[epoch 1/20] Avg. Loss for last 500 samples = inf\n",
      "[epoch 2/20] Avg. Loss for last 500 samples = 2.362351\n",
      "[epoch 3/20] Avg. Loss for last 500 samples = 2.327593\n",
      "[epoch 4/20] Avg. Loss for last 500 samples = 2.312582\n",
      "[epoch 5/20] Avg. Loss for last 500 samples = 2.318265\n",
      "[epoch 6/20] Avg. Loss for last 500 samples = 2.308613\n",
      "[epoch 7/20] Avg. Loss for last 500 samples = 2.317080\n",
      "[epoch 8/20] Avg. Loss for last 500 samples = 2.291474\n",
      "[epoch 9/20] Avg. Loss for last 500 samples = 2.257941\n",
      "[epoch 10/20] Avg. Loss for last 500 samples = 2.237626\n",
      "[epoch 11/20] Avg. Loss for last 500 samples = 2.240568\n",
      "[epoch 12/20] Avg. Loss for last 500 samples = 2.156755\n"
     ]
    }
   ],
   "source": [
    "# set here the size of the RNN state:\n",
    "stateSize = 40\n",
    "# set here the size of the binary strings to be used for training:\n",
    "k=2 # we want the RNN to remember the number at 2nd position\n",
    "minSeqLength = 6\n",
    "maxSeqLength = 16\n",
    "\n",
    "## sequenceLengths would be in range in range minSeqLength - maxSeqLength\n",
    "\n",
    "\n",
    "# create the model:\n",
    "model = Memorize(stateSize)\n",
    "print ('Model initialized')\n",
    "\n",
    "# create the loss-function:\n",
    "lossFunction = nn.CrossEntropyLoss() # or nn.CrossEntropyLoss() -- see question #2 below\n",
    "\n",
    "# uncomment below to change the optimizers:\n",
    "#optimizer = optim.SGD(model.parameters(), lr=3e-2, momentum=0.8)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01)\n",
    "iterations = 1000\n",
    "min_epochs = 20\n",
    "num_epochs,totalLoss = 0,float(\"inf\")\n",
    "lossList = []\n",
    "while num_epochs < min_epochs:\n",
    "    print(\"[epoch %d/%d] Avg. Loss for last 500 samples = %lf\"%(num_epochs+1,min_epochs,totalLoss))\n",
    "    num_epochs += 1\n",
    "    totalLoss = 0\n",
    "    for i in range(0,iterations):\n",
    "        # get a new random training sample:\n",
    "        sequenceLength = random.randint(minSeqLength,maxSeqLength)\n",
    "        x,y = getSample(sequenceLength,k)\n",
    " \n",
    "        model.zero_grad()\n",
    "\n",
    "        pred = model(x)\n",
    "\n",
    "        # compute the loss:\n",
    "        loss = lossFunction(pred,y)\n",
    "        totalLoss += loss.data\n",
    "        optimizer.zero_grad()\n",
    "        # perform the backward pass:\n",
    "        loss.backward()\n",
    "        # update the weights:\n",
    "        optimizer.step()\n",
    "    totalLoss=totalLoss/iterations\n",
    "    lossList.append(int(totalLoss))\n",
    "print('Training finished!')\n",
    "epochs =  np.arange(1,21)\n",
    "# plot the loss over epcohs:\n",
    "plt.plot(epochs,lossList)\n",
    "plt.xlabel('epochs'); plt.ylabel('loss'); plt.xticks(epochs,epochs)\n",
    "plt.ylim([0,5]); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cb9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSeqL = 6\n",
    "x,y = getSample(testSeqL,k,testFlag=True)\n",
    "\n",
    "pred = model(x)\n",
    "ind=  torch.argmax(pred)\n",
    "print ( 'number at kth position is ',int(ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18658f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
